{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52769ac5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Using cached llama_index-0.12.34-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-graph-stores-neo4j\n",
      "  Using cached llama_index_graph_stores_neo4j-0.4.6-py3-none-any.whl.metadata (694 bytes)\n",
      "Collecting graspologic\n",
      "  Using cached graspologic-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy==1.24.4\n",
      "  Downloading numpy-1.24.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting scipy==1.12.0\n",
      "  Downloading scipy-1.12.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
      "Collecting future\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
      "  Using cached llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13,>=0.12.34 (from llama-index)\n",
      "  Downloading llama_index_core-0.12.34.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Downloading openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting aiohttp<4,>=3.8.6 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading aiohttp-3.11.18-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httpx (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading pillow-11.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pydantic>=2.8.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting pyyaml>=6.0.1 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm<5,>=4.66.1 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (4.13.2)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading multidict-6.4.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting jinja2 (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.10/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (4.3.7)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.2.2)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting neo4j<6.0.0,>=5.16.0 (from llama-index-graph-stores-neo4j)\n",
      "  Using cached neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting pytz (from neo4j<6.0.0,>=5.16.0->llama-index-graph-stores-neo4j)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting POT<0.10,>=0.9 (from graspologic)\n",
      "  Downloading POT-0.9.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting anytree<3.0.0,>=2.12.1 (from graspologic)\n",
      "  Using cached anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting beartype<0.19.0,>=0.18.5 (from graspologic)\n",
      "  Using cached beartype-0.18.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting gensim<5.0.0,>=4.3.2 (from graspologic)\n",
      "  Downloading gensim-4.3.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.2 kB)\n",
      "Collecting graspologic-native<2.0.0,>=1.2.1 (from graspologic)\n",
      "  Using cached graspologic_native-1.2.5-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (2.6 kB)\n",
      "Collecting hyppo<0.5.0,>=0.4.0 (from graspologic)\n",
      "  Using cached hyppo-0.4.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting joblib<2.0.0,>=1.4.2 (from graspologic)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting matplotlib<4.0.0,>=3.8.4 (from graspologic)\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of graspologic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting graspologic\n",
      "  Using cached graspologic-3.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting POT<0.8.0,>=0.7.0 (from graspologic)\n",
      "  Using cached POT-0.7.0.post1.tar.gz (176 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beartype<0.11.0,>=0.10.4 (from graspologic)\n",
      "  Using cached beartype-0.10.4-py3-none-any.whl.metadata (256 kB)\n",
      "Collecting hyppo<0.4.0,>=0.3.2 (from graspologic)\n",
      "  Using cached hyppo-0.3.2.tar.gz (84 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting graspologic\n",
      "  Using cached graspologic-3.3.0.tar.gz (5.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beartype>=0.10.0 (from graspologic)\n",
      "  Using cached beartype-0.20.2-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting hyppo>=0.3.2 (from graspologic)\n",
      "  Using cached hyppo-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting seaborn>=0.11.0 (from graspologic)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn>=0.22.0 (from graspologic)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting statsmodels>=0.13.2 (from graspologic)\n",
      "  Downloading statsmodels-0.14.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting umap-learn>=0.4.6 (from graspologic)\n",
      "  Using cached umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim<5.0.0,>=4.3.2->graspologic)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting numba>=0.46 (from hyppo>=0.3.2->graspologic)\n",
      "  Downloading numba-0.61.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "Collecting autograd>=1.3 (from hyppo>=0.3.2->graspologic)\n",
      "  Using cached autograd-1.7.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Using cached llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.21->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4.0.0,>=3.8.4->graspologic)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<4.0.0,>=3.8.4->graspologic)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4.0.0,>=3.8.4->graspologic)\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<4.0.0,>=3.8.4->graspologic)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4.0.0,>=3.8.4->graspologic)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (2.9.0.post0)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.46->hyppo>=0.3.2->graspologic)\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.8.4->graspologic) (1.17.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.22.0->graspologic)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading greenlet-3.2.1-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->graspologic)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.4.6->graspologic)\n",
      "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading numpy-1.24.4-cp310-cp310-macosx_11_0_arm64.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-macosx_12_0_arm64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index-0.12.34-py3-none-any.whl (7.0 kB)\n",
      "Using cached llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.12.34.post1-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.18-cp310-cp310-macosx_11_0_arm64.whl (457 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached banks-2.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading multidict-6.4.3-cp310-cp310-macosx_11_0_arm64.whl (37 kB)\n",
      "Downloading openai-1.77.0-py3-none-any.whl (662 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.0/662.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp310-cp310-macosx_11_0_arm64.whl (321 kB)\n",
      "Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading yarl-1.20.0-cp310-cp310-macosx_11_0_arm64.whl (94 kB)\n",
      "Using cached llama_index_graph_stores_neo4j-0.4.6-py3-none-any.whl (17 kB)\n",
      "Using cached neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anytree-2.13.0-py3-none-any.whl (45 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached beartype-0.20.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading frozenlist-1.6.0-cp310-cp310-macosx_11_0_arm64.whl (122 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading gensim-4.3.3-cp310-cp310-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached graspologic_native-1.2.5-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (648 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached hyppo-0.5.1-py3-none-any.whl (165 kB)\n",
      "Using cached autograd-1.7.0-py3-none-any.whl (52 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
      "Using cached llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.6.21-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading numba-0.61.2-cp310-cp310-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp310-cp310-macosx_11_0_arm64.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp310-cp310-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading POT-0.9.5-cp310-cp310-macosx_11_0_arm64.whl (344 kB)\n",
      "Downloading propcache-0.3.1-cp310-cp310-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.1-cp310-cp310-macosx_11_0_universal2.whl (267 kB)\n",
      "Downloading statsmodels-0.14.4-cp310-cp310-macosx_11_0_arm64.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tiktoken-0.9.0-cp310-cp310-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Building wheels for collected packages: graspologic\n",
      "  Building wheel for graspologic (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for graspologic: filename=graspologic-3.3.0-py3-none-any.whl size=5201825 sha256=731cc0da912d036ae46f8c8c7c963f7734fcc75157bfad82666f830d624c7eac\n",
      "  Stored in directory: /Users/suryagunukula/Library/Caches/pip/wheels/87/d1/8c/f371fb5cb6f387cbe0af31a94158fa55ecfd837daaf3b2a213\n",
      "Successfully built graspologic\n",
      "Installing collected packages: striprtf, pytz, filetype, dirtyjson, wrapt, urllib3, tzdata, typing-inspection, tqdm, threadpoolctl, tenacity, sqlalchemy, soupsieve, sniffio, regex, pyyaml, python-dotenv, pypdf, pyparsing, pydantic-core, propcache, pillow, numpy, networkx, neo4j, mypy-extensions, multidict, marshmallow, MarkupSafe, llvmlite, kiwisolver, joblib, jiter, idna, h11, greenlet, graspologic-native, future, fsspec, frozenlist, fonttools, distro, cycler, colorama, click, charset-normalizer, certifi, beartype, attrs, async-timeout, anytree, annotated-types, aiohappyeyeballs, yarl, typing-inspect, smart-open, scipy, requests, pydantic, patsy, pandas, numba, nltk, jinja2, httpcore, griffe, deprecated, contourpy, beautifulsoup4, autograd, anyio, aiosignal, tiktoken, statsmodels, scikit-learn, POT, matplotlib, httpx, gensim, dataclasses-json, banks, aiohttp, seaborn, pynndescent, openai, llama-index-core, llama-cloud, hyppo, umap-learn, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-graph-stores-neo4j, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, graspologic, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104/104\u001b[0m [llama-index]\u001b[32m 99/104\u001b[0m [graspologic]readers-file]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 POT-0.9.5 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 anytree-2.13.0 async-timeout-5.0.1 attrs-25.3.0 autograd-1.7.0 banks-2.1.2 beartype-0.20.2 beautifulsoup4-4.13.4 certifi-2025.4.26 charset-normalizer-3.4.2 click-8.1.8 colorama-0.4.6 contourpy-1.3.2 cycler-0.12.1 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 filetype-1.2.0 fonttools-4.57.0 frozenlist-1.6.0 fsspec-2025.3.2 future-1.0.0 gensim-4.3.3 graspologic-3.3.0 graspologic-native-1.2.5 greenlet-3.2.1 griffe-1.7.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 hyppo-0.5.1 idna-3.10 jinja2-3.1.6 jiter-0.9.0 joblib-1.4.2 kiwisolver-1.4.8 llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-0.12.34 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.34.post1 llama-index-embeddings-openai-0.3.1 llama-index-graph-stores-neo4j-0.4.6 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.21 llvmlite-0.44.0 marshmallow-3.26.1 matplotlib-3.10.1 multidict-6.4.3 mypy-extensions-1.1.0 neo4j-5.28.1 networkx-3.4.2 nltk-3.9.1 numba-0.61.2 numpy-1.24.4 openai-1.77.0 pandas-2.2.3 patsy-1.0.1 pillow-11.2.1 propcache-0.3.1 pydantic-2.11.4 pydantic-core-2.33.2 pynndescent-0.5.13 pyparsing-3.2.3 pypdf-5.4.0 python-dotenv-1.1.0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 scikit-learn-1.6.1 scipy-1.12.0 seaborn-0.13.2 smart-open-7.1.0 sniffio-1.3.1 soupsieve-2.7 sqlalchemy-2.0.40 statsmodels-0.14.4 striprtf-0.0.26 tenacity-9.1.2 threadpoolctl-3.6.0 tiktoken-0.9.0 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.0 tzdata-2025.2 umap-learn-0.5.7 urllib3-2.4.0 wrapt-1.17.2 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index llama-index-graph-stores-neo4j graspologic numpy==1.24.4 scipy==1.12.0 future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfc6782",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevron: Best Of Breed</td>\n",
       "      <td>2031-04-06T01:36:32.000000000+00:00</td>\n",
       "      <td>JHVEPhoto Like many companies in the O&amp;G secto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FirstEnergy (NYSE:FE) Posts Earnings Results</td>\n",
       "      <td>2030-04-29T06:55:28.000000000+00:00</td>\n",
       "      <td>FirstEnergy (NYSE:FE – Get Rating) posted its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dáil almost suspended after Sinn Féin TD put p...</td>\n",
       "      <td>2023-06-15T14:32:11.000000000+00:00</td>\n",
       "      <td>The Dáil was almost suspended on Thursday afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Epic’s latest tool can animate hyperrealistic ...</td>\n",
       "      <td>2023-06-15T14:00:00.000000000+00:00</td>\n",
       "      <td>Today, Epic is releasing a new tool designed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EU to Ban Huawei, ZTE from Internal Commission...</td>\n",
       "      <td>2023-06-15T13:50:00.000000000+00:00</td>\n",
       "      <td>The European Commission is planning to ban equ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                             Chevron: Best Of Breed   \n",
       "1       FirstEnergy (NYSE:FE) Posts Earnings Results   \n",
       "2  Dáil almost suspended after Sinn Féin TD put p...   \n",
       "3  Epic’s latest tool can animate hyperrealistic ...   \n",
       "4  EU to Ban Huawei, ZTE from Internal Commission...   \n",
       "\n",
       "                                  date  \\\n",
       "0  2031-04-06T01:36:32.000000000+00:00   \n",
       "1  2030-04-29T06:55:28.000000000+00:00   \n",
       "2  2023-06-15T14:32:11.000000000+00:00   \n",
       "3  2023-06-15T14:00:00.000000000+00:00   \n",
       "4  2023-06-15T13:50:00.000000000+00:00   \n",
       "\n",
       "                                                text  \n",
       "0  JHVEPhoto Like many companies in the O&G secto...  \n",
       "1  FirstEnergy (NYSE:FE – Get Rating) posted its ...  \n",
       "2  The Dáil was almost suspended on Thursday afte...  \n",
       "3  Today, Epic is releasing a new tool designed t...  \n",
       "4  The European Commission is planning to ban equ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document \n",
    "\n",
    "news = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\"\n",
    ")[:50]\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5600e71b-8e0a-4f51-8724-40a2587e9462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 11fc9238-eaec-466a-bf41-607cf8dd6498\n",
      "Text: Chevron: Best Of Breed: JHVEPhoto Like many companies in the O&G\n",
      "sector, the stock of Chevron (NYSE:CVX) has declined about 10% over\n",
      "the past 90-days despite the fact that Q2 consensus earnings estimates\n",
      "have risen sharply (~25%) during that same time frame. Over the years,\n",
      "Chevron has kept a very strong balance sheet. That allowed the...\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    Document(text=f\"{row['title']}: {row['text']}\")\n",
    "    for i, row in news.iterrows()\n",
    "]\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580aaee5-b255-4ee1-9913-6d0d06a1b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model = \"llama3\",\n",
    "    base_url = \"http://localhost:11434\",\n",
    "    request_timeout = 120.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec060278-a124-45c1-b475-1b7056619ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio \n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import Any, List, Callable, Optional, Union, Dict \n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    defaults_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode, \n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY, \n",
    "    Relation\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT, \n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field \n",
    "\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_path_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        llm: Optional[LLM] = None, \n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm = llm or Settings.llm,\n",
    "            extract_prompt = extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn = parse_fn,\n",
    "            num_workers = num_workers,\n",
    "            max_paths_per_chunk = max_paths_per_chunk\n",
    "        )\n",
    "\n",
    "    @classmethod \n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[Node]:\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.appends(self._aextract(node))\n",
    "        return await run_jobs(\n",
    "            jobs, \n",
    "            workers = self.num_workers,\n",
    "            show_progress = show_progress,\n",
    "            desc = \"Extracting paths from text\"\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        assert hasattr(node, \"text)\n",
    "\n",
    "        text = node.get_content(metadata_mode = \"llm\")\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt, \n",
    "                text=text, \n",
    "                max_knowledge_triplets = self.max_paths_per_chunk\n",
    "            )\n",
    "        except ValueError: \n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6df3e-9f89-4280-969d-bd1eb44e1020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6ad77-7101-40be-931f-1b334559aa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv-graphrag-env)",
   "language": "python",
   "name": "uv-graphrag-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
